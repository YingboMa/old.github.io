---
layout: post
title:  "First Evaluations 1 Post"
date:   2018-06-10 15:52:40 -0700
categories: update
---

# Introduction
I am interested in stiff equations and time stepping for partial differential
equations. During the this first period of GSoC, I implemented the stiffness
detection and automatic switching algorithm, Adams-Bashforth-Moulton method in
Nordsieck representation, and touched upon ROCK
(Runge-Kutta-Orthogonal-Chebyshev) methods. The methods are all centered around
time stepping for stiff equations.  For instance, the stiffness detection and
automatic switching algorithm can let users solve problems with unknown natures
more efficiently, as the solver can automatically select a suitable method.
ROCK is a family of methods that optimizes for stability region of the
Runge-Kutta methods and utilizes stiffness detection to pick a suitable stage
number to avoid unnecessary function evaluations. Nordsieck formulation for
multi-step methods is used in `SUNDIALS`'s `CVODE` program, it is
perhaps the most widely used method for stiff equations because of its
efficiency. They have BDF methods that is in the FLC
(fixed-leading-coefficient) form to avoid extra matrix factorization in
Newton's iteration. I finished the adaptive Adam-Bashforth-Moulton method in
Nordsieck form, and I plan to finish variable order adaptive step-size FLC BDF
by the end of the next GSoC evaluations.

# The Stiffness Detection and Automatic Switching Algorithm
The basic idea of stiffness detection is to estimate the spectral radius for
the system $u'=Ju$, where $J$ is the linearized operator for the ordinary
differential equation system at a fixed time. Higham and
Trefethen~\cite{stiffode} pointed out that an ODE system is stiff when the
pseudospectrum of $J$ has large radii while it has a small abscissa. Although
stiffness cannot be characterized by merely the spectral radius of $J$, it is
cheap to do power iterations or to calculate the infinity norm of a matrix, while
computing the pseudospectra of a linear operator is very costly. Thus, in
practice, people only use power iterations or the infinity norm to quantify the
stiffness of the system. Naturally, one can impose an automatic switching
algorithm from the information that is given by the stiffness detection
routine. In this way, a solver is able to intelligently select a suitable
method during the integration of the system.

The simplest automatic stiffness detection on explicit Runge-Kutta algorithms
is proposed by Ernst Hairer. One can use the difference between two different
`K`s that have time same time to approximate the dominant eigenvalue of the
Jacobian matrix of the function `f(u, t)` when `norm(v)` is small. For explicit
Runge-Kutta methods like Dormand-Prince and Tsitouras 5/4 pairs, there is the
relation `c_6 = c_7 = 1`.  Naturally, one can classify a problem to be stiff
when `hρ/∂S > 1$.  Where `∂S` is the width of the stability domain of the
Runge-Kutta algorithm. A simple implementation reads:
{% highlight julia %}
g6 = uprev+dt*(a61*k1+a62*k2+a63*k3+a64*k4+a65*k5)
k6 = f(g6, p, t+dt)
g7 = u
rhou = integrator.opts.internalnorm(k7 - k6)
rhol = integrator.opts.internalnorm(g7 - g6)
integrator.eigen_est = rhou/rhol
{% endhighlight %}
Implicit methods already have Jacobian matrix available, so the implementation
is trivial. It reads
{% highlight julia %}
is_compos && (integrator.eigen_est = norm(J, Inf))
{% endhighlight %}

The switching algorithm then utilizes the information from
`integrator.eigen_est` to choose an efficient solver.

# Nordsieck Formulation
In the Nordsieck formulation of multi-step methods we first need to find
interpolating polynomials `π₋₁` and `π`, which are the predictor and the
corrector polynomial respectively. While the predictor polynomial for the
Nordsieck formulation is exactly the Taylor expansion, there are some
variations in the corrector polynomials, which makes this method versatile and
flexible.
